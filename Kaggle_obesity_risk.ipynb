{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkuX4KzXJlnezrCVq+txVl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TetianaZabolotko/MLtrainings/blob/main/Kaggle_obesity_risk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gd7tVkiFvHD3"
      },
      "outputs": [],
      "source": [
        "# Your Goal: The goal of this competition is to use various factors\n",
        "# to predict obesity risk in individuals, which is related to cardiovascular disease.\n",
        "# Good luck!\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/obesity_risk_data/train.csv')\n",
        "df_test = pd.read_csv('/content/obesity_risk_data/test.csv')\n",
        "# df_test = pd.read_csv('/content/obesity_risk_data/sample_submission.csv')\n",
        "\n",
        "print(f'The train dataset has {df_train.shape[0]}, the testset has {df_test.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "EZWUAoNHv0Vp",
        "outputId": "8777ed4c-5fb1-415a-8ee8-9d5505103106"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/obesity_risk_data/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3ea259aaa1fe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/obesity_risk_data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/obesity_risk_data/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# df_test = pd.read_csv('/content/obesity_risk_data/sample_submission.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The train dataset has {df_train.shape[0]}, the testset has {df_test.shape[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/obesity_risk_data/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display('Train:', df_train.head(10))\n",
        "display('Test:',df_test.head())"
      ],
      "metadata": {
        "id": "a95-s5QIwEna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe().to_csv('output.csv', index=False)"
      ],
      "metadata": {
        "id": "sZVitbgXwSZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "yphRrO_GwW0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "data = [\n",
        "    [\"FAVC\", \"Frequent consumption of high caloric food\"],\n",
        "    [\"FCVC\", \"Frequency of consumption of vegetables\"],\n",
        "    [\"NCP\", \"Number of main meals\"],\n",
        "    [\"CAEC\", \"Consumption of food between meals\"],\n",
        "    [\"CH20\", \"Consumption of water daily\"],\n",
        "    [\"CALC\", \"Consumption of alcohol\"],\n",
        "    [\"SCC\", \"Calories consumption monitoring\"],\n",
        "    [\"FAF\", \"Physical activity frequency\"],\n",
        "    [\"TUE\", \"Time using technology devices\"],\n",
        "    [\"MTRANS\", \"Transportation used\"]\n",
        "]\n",
        "headers = [\"Abbreviation\", \"Full Form\"]\n",
        "\n",
        "table = tabulate(data, headers, tablefmt=\"pipe\")\n",
        "print(table)"
      ],
      "metadata": {
        "id": "BYeaMxAIwZqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summary(df):\n",
        "    summ = pd.DataFrame(df.dtypes, columns=['data type'])\n",
        "    summ['#missing'] = df.isnull().sum().values\n",
        "    summ['Duplicate'] = df.duplicated().sum()\n",
        "    summ['#unique'] = df.nunique().values\n",
        "    desc = pd.DataFrame(df.describe(include='all').transpose())\n",
        "    summ['min'] = desc['min'].values\n",
        "    summ['max'] = desc['max'].values\n",
        "    summ['avg'] = desc['mean'].values\n",
        "    summ['std dev'] = desc['std'].values\n",
        "    summ['top value'] = desc['top'].values\n",
        "    summ['Freq'] = desc['freq'].values\n",
        "\n",
        "    return summ"
      ],
      "metadata": {
        "id": "WuwMmPcNwdKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(df_train.drop(columns=[\"id\"])).style.background_gradient()"
      ],
      "metadata": {
        "id": "4fqE2-D3w1AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def showplot(columnname):\n",
        "    plt.rcParams['figure.facecolor'] = 'white'\n",
        "    plt.rcParams['axes.facecolor'] = 'white'\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    ax = ax.flatten()\n",
        "    value_counts = df_train[columnname].value_counts()\n",
        "    labels = value_counts.index.tolist()\n",
        "    colors =[\"#4caba4\", \"#d68c78\",'#a3a2a2','#ab90a0', '#e6daa3', '#6782a8', '#8ea677']\n",
        "\n",
        "    # Donut Chart\n",
        "    wedges, texts, autotexts = ax[0].pie(\n",
        "        value_counts, autopct='%1.1f%%',textprops={'size': 9, 'color': 'white','fontweight':'bold' }, colors=colors,\n",
        "        wedgeprops=dict(width=0.35),  startangle=80,   pctdistance=0.85  )\n",
        "    # circle\n",
        "    centre_circle = plt.Circle((0, 0), 0.6, fc='white')\n",
        "    ax[0].add_artist(centre_circle)\n",
        "\n",
        "    # Count Plot\n",
        "    sns.countplot(data=df_train, y=columnname, ax=ax[1], palette=colors, order=labels)\n",
        "    for i, v in enumerate(value_counts):\n",
        "        ax[1].text(v + 1, i, str(v), color='black',fontsize=10, va='center')\n",
        "    sns.despine(left=True, bottom=True)\n",
        "    plt.yticks(fontsize=9,color='black')\n",
        "    ax[1].set_ylabel(None)\n",
        "    plt.xlabel(\"\")\n",
        "    plt.xticks([])\n",
        "    fig.suptitle(columnname, fontsize=15, fontweight='bold')\n",
        "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JwLTxLi8X_bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot(\"NObeyesdad\")"
      ],
      "metadata": {
        "id": "N2d0Y4BeYWO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(df_train.describe(include='all').transpose())\n",
        "df"
      ],
      "metadata": {
        "id": "YfmmY1nAZQZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot('Gender')"
      ],
      "metadata": {
        "id": "f7rWDR7TgEWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot(\"family_history_with_overweight\")"
      ],
      "metadata": {
        "id": "mB0KuQEXgHQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot(\"FAVC\")"
      ],
      "metadata": {
        "id": "vRfd7MELgO6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot(\"CAEC\")"
      ],
      "metadata": {
        "id": "XZ4_x8ktgSXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot(\"SMOKE\")"
      ],
      "metadata": {
        "id": "NigUfmtxgU-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot(\"SCC\")"
      ],
      "metadata": {
        "id": "wz_URhHugasQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot(\"CALC\")"
      ],
      "metadata": {
        "id": "OxwSSVlVgkeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showplot(\"MTRANS\")"
      ],
      "metadata": {
        "id": "pzRc7Y9JgoH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for distributions\n",
        "numeric_columns = df_train.select_dtypes(include=['float64', 'int64']).drop(columns=['id'], axis=1)\n",
        "def dist(train_dataset,columns_list, rows, cols):\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(24, 10))\n",
        "    plt.suptitle('Distribution for numerical features: Train vs Original Dataset', fontsize=16, fontweight='bold')\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for i, col in enumerate(columns_list):\n",
        "        sns.kdeplot(train_dataset[col], ax=axs[i], fill=True, alpha=0.5, linewidth=0.5, color='#05b0a3', label='Train')\n",
        "        # sns.kdeplot(original_dataset[col], ax=axs[i], fill=True, alpha=0.5, linewidth=0.5, color='#d68c78', label='Original')\n",
        "        # axs[i].set_title(f'{col}, Train skewness: {train_dataset[col].skew():.2f}\\n Original skewness: {original_dataset[col].skew():.2f}')\n",
        "        axs[i].legend()\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "bwn_NDBqgsKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist(train_dataset=df_train, columns_list=numeric_columns.columns, rows=2, cols=4)"
      ],
      "metadata": {
        "id": "ejTMqMspgtu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['#1f77b4', '#fc6c44', '#2b8a2b', '#fc7c7c', '#9467bd', '#4ba4ad', '#c7ad18', '#7f7f7f', '#69d108']\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
        "ax1 = sns.scatterplot(x=df_train['Height'], y=df_train['Age'], hue=\"NObeyesdad\",\n",
        "                       data=df_train, palette=colors, edgecolor='grey', alpha=0.8, s=9, ax=axes[0])\n",
        "axes[0].set_title('Height vs Age')\n",
        "ax2 = sns.scatterplot(x=df_train['Height'], y=df_train['Weight'], hue=\"NObeyesdad\",\n",
        "                       data=df_train, palette=colors, edgecolor='grey', alpha=0.8, s=9, ax=axes[1])\n",
        "axes[1].set_title('Height vs Weight')\n",
        "ax3 = sns.scatterplot(x=df_train['Age'], y=df_train['Weight'], hue=\"NObeyesdad\",\n",
        "                       data=df_train, palette=colors, edgecolor='grey', alpha=0.8, s=9, ax=axes[2])\n",
        "axes[2].set_title('Age vs Weight')\n",
        "for ax in axes.flatten():\n",
        "    ax.get_legend().remove()\n",
        "handles, labels = ax1.get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=len(df_train['NObeyesdad'].unique()),\n",
        "           title='')\n",
        "fig.suptitle('Age, Height, Weight against Target', fontsize=20)\n",
        "fig.subplots_adjust(bottom=0.5, top=0.9, hspace=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9sCuRRirhNM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "df_train['BMI']=  df_train['Weight'] / df_train['Height']**2\n",
        "ax1 = axes[0]\n",
        "df_sort = df_train.groupby('NObeyesdad')['BMI'].mean().sort_values(ascending=False).index\n",
        "sns.barplot(x='BMI', y='NObeyesdad', data=df_train, palette='light:#4caba4_r', order=df_sort,\n",
        "            estimator=np.mean, ci=None, errwidth=0, ax=ax1)\n",
        "for p in ax1.patches:\n",
        "    ax1.annotate(f'{p.get_width():.2f}', (p.get_x() + p.get_width() / 2., p.get_y() + p.get_height()),\n",
        "                ha='center', va='center', xytext=(0, 20), textcoords='offset points', fontsize=10, color='black')\n",
        "ax1.set_title('Mean BMI by NObeyesdad')\n",
        "ax1.set_xlabel('BMI')\n",
        "ax1.set_ylabel('')\n",
        "sns.despine(left=True, bottom=True, ax=ax1)\n",
        "\n",
        "# Violin Plot\n",
        "ax2 = axes[1]\n",
        "sns.violinplot(x='BMI', y='NObeyesdad', data=df_train, palette='light:#4caba4_r', order=df_sort, ax=ax2)\n",
        "ax2.set_title('Distribution of BMI by NObeyesdad')\n",
        "ax2.set_ylabel(\"\")\n",
        "plt.yticks([])\n",
        "sns.despine(left=True, bottom=True, ax=ax2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KbHIzWfzhUdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.groupby('NObeyesdad')['BMI'].describe().reset_index().style.background_gradient()"
      ],
      "metadata": {
        "id": "65XwkXFWhzfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "ax1 = axes[0]\n",
        "df_sort = df_train.groupby('NObeyesdad')['Age'].mean().sort_values(ascending=False).index\n",
        "sns.barplot(x='Age', y='NObeyesdad', data=df_train, palette='light:#4caba4_r', order=df_sort,\n",
        "            estimator=np.mean, ci=None, errwidth=0, ax=ax1)\n",
        "for p in ax1.patches:\n",
        "    ax1.annotate(f'{p.get_width():.2f}', (p.get_x() + p.get_width() / 2., p.get_y() + p.get_height()),\n",
        "                ha='center', va='center', xytext=(0, 20), textcoords='offset points', fontsize=10, color='black')\n",
        "ax1.set_title('Mean Age by NObeyesdad')\n",
        "ax1.set_xlabel('Age')\n",
        "ax1.set_ylabel('')\n",
        "sns.despine(left=True, bottom=True, ax=ax1)\n",
        "\n",
        "# Violin Plot\n",
        "ax2 = axes[1]\n",
        "sns.violinplot(x='Age', y='NObeyesdad', data=df_train, palette='light:#4caba4_r', order=df_sort, ax=ax2)\n",
        "ax2.set_title('Distribution of Age by NObeyesdad')\n",
        "ax2.set_ylabel(\"\")\n",
        "plt.yticks([])\n",
        "sns.despine(left=True, bottom=True, ax=ax2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ph8Rm5K6h4ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_tab = pd.crosstab(df_train['NObeyesdad'], df_train['MTRANS'])\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(cross_tab, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
        "plt.title(' NObeyesdad and MTRANS')\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bZE--FjRh8KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "ax = sns.countplot(x='Gender', hue='NObeyesdad', data=df_train, palette=colors, dodge=True)\n",
        "plt.title('Distribution of NObeyesdad across Gender')\n",
        "sns.despine(left=True, bottom=False)\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.yticks([])\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.annotate(f'{round(height)}', (p.get_x() + p.get_width() / 2., height),\n",
        "                ha='center', va='center', xytext=(0, 8), textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ruQ6rrPhh_ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "df_train['BMI']=  df_train['Weight'] / df_train['Height']**2\n",
        "ax1 = axes[0]\n",
        "df_sort = df_train.groupby('Gender')['BMI'].mean().sort_values(ascending=False).index\n",
        "sns.barplot(x='BMI', y='Gender', data=df_train, palette='light:#4caba4_r', order=df_sort,\n",
        "            estimator=np.mean, ci=None, errwidth=0, ax=ax1)\n",
        "for p in ax1.patches:\n",
        "    ax1.annotate(f'{p.get_width():.2f}', (p.get_x() + p.get_width() / 2., p.get_y() + p.get_height()),\n",
        "                ha='center', va='center', xytext=(0, 50), textcoords='offset points', fontsize=10, color='black')\n",
        "ax1.set_title('Mean BMI by Gender')\n",
        "ax1.set_xlabel('BMI')\n",
        "ax1.set_ylabel('')\n",
        "sns.despine(left=True, bottom=True, ax=ax1)\n",
        "# Violin Plot\n",
        "ax2 = axes[1]\n",
        "sns.violinplot(x='BMI', y='Gender', data=df_train, palette='light:#4caba4_r', order=df_sort, ax=ax2)\n",
        "ax2.set_title('Distribution of BMI by Gender')\n",
        "ax2.set_ylabel(\"\")\n",
        "plt.yticks([])\n",
        "sns.despine(left=True, bottom=True, ax=ax2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b6v2k6rZiMvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Correlation heatmap\n",
        "# numeric_columns_original = original.select_dtypes(include=np.number)\n",
        "# numeric_columns_train = df_train.select_dtypes(include=np.number).drop(['id','BMI'], axis=1)\n",
        "# # original\n",
        "# corr_original = numeric_columns_original.corr(method='pearson')\n",
        "# mask_original = np.triu(np.ones_like(corr_original))\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "# sns.heatmap(corr_original, annot=True, fmt='.2f', mask=mask_original, cmap='copper_r', cbar=None, linewidth=2, ax=axes[0])\n",
        "# axes[0].set_title('Original Dataset', fontsize=16, fontweight='bold')\n",
        "\n",
        "# # Train\n",
        "# corr_train = numeric_columns_train.corr(method='pearson')\n",
        "# mask_train = np.triu(np.ones_like(corr_train))\n",
        "# sns.heatmap(corr_train, annot=True, fmt='.2f', mask=mask_train, cmap='copper_r', cbar=None, linewidth=2, ax=axes[1])\n",
        "# axes[1].set_title('Train Dataset', fontsize=16, fontweight='bold')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "WxuPuMdriQWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2AeGvCzioscU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmZXQG1-o3Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for presence of outliers in each feature\n",
        "numeric_columns = df_train.select_dtypes(include=['float64', 'int64']).drop(columns=['id'], axis=1)\n",
        "fig = plt.figure(figsize=[32,10])\n",
        "plt.suptitle('Outliers in the data', fontsize=18, fontweight='bold')\n",
        "fig.subplots_adjust(top=0.92);\n",
        "fig.subplots_adjust(hspace=0.5, wspace=0.4);\n",
        "for i ,col in enumerate(numeric_columns):\n",
        "    ax = fig.add_subplot(3,3, i+1);\n",
        "    ax = sns.boxplot(data = df_train, x=col ,  color= colors[i]);\n",
        "    ax.set_title(f'{col}')\n",
        "    ax.set_xlabel(f'{col}')\n",
        "    ax.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "daQ4z8yuiWdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_variable_types(dataframe):\n",
        "    continuous_vars = []\n",
        "    categorical_vars = []\n",
        "\n",
        "    for column in dataframe.columns:\n",
        "        if dataframe[column].dtype == 'object':\n",
        "            categorical_vars.append(column)\n",
        "        else:\n",
        "            continuous_vars.append(column)\n",
        "\n",
        "    return continuous_vars, categorical_vars\n",
        "\n",
        "continuous_vars, categorical_vars = get_variable_types(df_train)\n",
        "categorical_vars.remove('NObeyesdad')"
      ],
      "metadata": {
        "id": "5IRgCjR-ifKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = df_train.drop(['id'], axis=1).drop_duplicates()\n",
        "test = df_test.drop(['id'], axis=1)"
      ],
      "metadata": {
        "id": "P3KM3CQgitNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.get_dummies(train, columns=categorical_vars, drop_first=True)\n",
        "test = pd.get_dummies(test, columns=categorical_vars, drop_first=True)"
      ],
      "metadata": {
        "id": "gLTNMR3ci36L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check the Shape of data\n",
        "print(f'The encoded Train dataset has {train.shape[0]} rows and {train.shape[1]} columns')\n",
        "print(f'The encoded Test dataset has {test.shape[0]} rows and {test.shape[1]} columns')"
      ],
      "metadata": {
        "id": "rDK5uUfPi64f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(['NObeyesdad'], axis=1)\n",
        "y = train['NObeyesdad']"
      ],
      "metadata": {
        "id": "ioXlZBPWi-GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2HD9yZ0DjB32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "c0eS1e-BjEtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_cat = df_train.loc[:, df_train.nunique() < 8].columns\n",
        "df_train[to_cat] = df_train[to_cat].astype(\"category\").copy()\n",
        "df_train.dtypes"
      ],
      "metadata": {
        "id": "QaHOlqTCo4ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameters obtained from Optuna optimization from notebook in comments\n",
        "# https://www.kaggle.com/code/moazeldsokyx/pgs4e2-highest-score-lgbm-hyperparameter-tuning/notebook\n",
        "\n",
        "best_params = {\n",
        "    \"objective\": \"multiclass\",          # Objective function for the model\n",
        "    \"metric\": \"multi_logloss\",          # Evaluation metric\n",
        "    \"verbosity\": -1,                    # Verbosity level (-1 for silent)\n",
        "    \"boosting_type\": \"gbdt\",            # Gradient boosting type\n",
        "    \"random_state\": 42,       # Random state for reproducibility\n",
        "    \"num_class\": 7,                     # Number of classes in the dataset\n",
        "    'learning_rate': 0.01197852738297134,  # Learning rate for gradient boosting\n",
        "    'n_estimators': 509,                # Number of boosting iterations\n",
        "    'lambda_l1': 0.009715116714365275,  # L1 regularization term\n",
        "    'lambda_l2': 0.03853395161282091,   # L2 regularization term\n",
        "    'max_depth': 11,                    # Maximum depth of the trees\n",
        "    'colsample_bytree': 0.7364306508830604,  # Fraction of features to consider for each tree\n",
        "    'subsample': 0.9529973839959326,    # Fraction of samples to consider for each boosting iteration\n",
        "    'min_child_samples': 17             # Minimum number of data needed in a leaf\n",
        "}"
      ],
      "metadata": {
        "id": "m0t7h8SLS7Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_classifier = LGBMClassifier(**best_params)\n",
        "lgbm_classifier.fit(X_train,y_train)\n",
        "y_pred = lgbm_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "DsCOIBz7T0H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "hxfgjEuObhw8",
        "outputId": "f0f56e0e-4dad-4217-e1e7-4a593696824f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'accuracy_score' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-86e1b10703d2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "vpPBdwkbbvs2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}